{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb891f59-8f22-4c2d-a40f-8af892b5422c",
   "metadata": {},
   "source": [
    "# Diffusion Based Models (2022)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0fa96d-230c-453c-94ee-8096abbfed00",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Idea"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40dde86-2847-40b8-aa41-a0af8f9aaf69",
   "metadata": {},
   "source": [
    "**Main Idea**\n",
    "\n",
    "Diffusion Based models are a type of generative models that create high-quality data by gradually refining noise into structured patterns, typically using a process that reverses diffusion, which is the gradual mixing of substances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c2ca70-b6f5-435d-9524-767f3d02e64a",
   "metadata": {},
   "source": [
    "**Pros**\n",
    "\n",
    "1. **Detail Preservation:** Effective at maintaining details in generated images or patterns\n",
    "2. **Control:** Allow more control over the generation process through conditioning\n",
    "3. **Stability:** Tend to be more stable during training compared to traditional GANs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4cee60f-57fa-4db2-ac5a-f4812510c996",
   "metadata": {},
   "source": [
    "**Cons**\n",
    "\n",
    "- **Complexity:** The underlying mechanisms can be complex and computationally intensive\n",
    "- **Hyperparameter Sensitivity:** May require careful tuning of hyperparameters for optimal performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde835d0-8220-4f3d-8f4c-fa728b431a55",
   "metadata": {},
   "source": [
    "**Creator**\n",
    "\n",
    "Stable Diffusion — модель генерации изображений, созданная при сотрудничестве Runway ML и CompViz group в LMU Munich с использованием ресурсов Stability AI\n",
    "\n",
    "- https://github.com/Stability-AI/generative-models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77074d1c-de4d-4e61-8c74-d7f799b71ceb",
   "metadata": {},
   "source": [
    "![https://www.linkedin.com/pulse/diffusion-model-generative-image-synthesis-yogeshwaran-singarasu-jgo4c/](content/img4001_SDidea.png \"SDidea\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628db56d-b0fc-463c-a080-ad360ed9164d",
   "metadata": {},
   "source": [
    "### Forward Diffusion Process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e9f9c2-a6de-4882-8d33-b64acb26655f",
   "metadata": {},
   "source": [
    "\r\n",
    "- A controlled, fixed process\r\n",
    "- Self-determined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1699bf-4211-43d4-92ce-e2f044a9c5e3",
   "metadata": {},
   "source": [
    "![https://theaisummer.com/diffusion-models/](content/img4002_Forward.png \"Forward\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da69dbb-d78b-4d86-b0b5-f99b7db662eb",
   "metadata": {},
   "source": [
    "$$ q(x_t | x_{t-1}) = \\mathcal{N}(x_t; \\mu_t = \\sqrt{1 - \\beta_t} x_{t-1}, \\Sigma_t = \\beta_t I) $$\n",
    "\n",
    "- $x_t$ — state of the image at time step $t$\n",
    "- $x_{t-1}$ — state of the image at the previous step $t-1$\n",
    "- $\\beta_t$ — diffusion coefficient at step $t$\n",
    "- $\\mu_t$ —  mean of the normal distribution\n",
    "- $\\Sigma_t$ —  covariance matrix of the normal distribution, where $I$ represents the identity matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6c9a93-9bdb-4764-9d5a-a58553db31de",
   "metadata": {},
   "source": [
    "![https://yang-song.net/blog/2021/score/](content/img4003_FNoising.gif \"FNoising\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9adac8b8-d8ee-46e9-b2a4-5b8a11c51ef4",
   "metadata": {},
   "source": [
    "- $x_t = \\sqrt{\\alpha_t} x_{t-1} + \\sqrt{1 - \\alpha_t} \\varepsilon_t, \\quad \\varepsilon_t \\sim \\mathcal{N}(0, I), \\quad \\alpha_t = 1 - \\beta_t $\n",
    "- $x_t = \\sqrt{\\bar{\\alpha}_t} x_0 + \\sqrt{1 - \\bar{\\alpha}_t} \\varepsilon, \\quad \\varepsilon \\sim \\mathcal{N}(0, I), \\quad \\bar{\\alpha}_t = \\prod_{i=1}^t \\alpha_i $\n",
    "- $x_{t-1} = \\frac{1}{\\sqrt{\\bar{\\alpha}_t}} \\left( x_t - \\frac{1 - \\alpha_t}{\\sqrt{1 - \\bar{\\alpha}_t}} \\varepsilon \\right) + \\tilde{\\beta}_t z, \\quad z \\sim \\mathcal{N}(0, I), \\quad \\tilde{\\beta}_t = \\frac{1 - \\bar{\\alpha}_{t-1}}{1 - \\bar{\\alpha}_t} \\beta_t$\n",
    "- $\\varepsilon$ - noise vector\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f141e8c7-00e1-48db-a7e2-807c15bdef77",
   "metadata": {},
   "source": [
    "### Reverse Diffusion Process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1478a010-5da7-4d1d-8dee-f51736cfd99d",
   "metadata": {},
   "source": [
    "- Trained by the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb131d1-5b76-4251-a623-28ee15d4e13e",
   "metadata": {},
   "source": [
    "![https://theaisummer.com/diffusion-models/](content/img4004_Reverse.png \"Reverse\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9979e832-632e-4185-ae08-15f4451962ca",
   "metadata": {},
   "source": [
    "![https://yang-song.net/blog/2021/score/](content/img4005_RNoising.gif \"RNoising\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f431fd6-53cd-4a92-a3a5-ff35679927ee",
   "metadata": {},
   "source": [
    "- $\\hat{x}_{t-1} = \\frac{1}{\\sqrt{\\bar{\\alpha}_t}} \\left( x_t - \\frac{1-\\alpha_t}{\\sqrt{1-\\bar{\\alpha}_t}} \\varepsilon_{\\theta}(x_t, t) \\right) + \\sigma_t z, \\quad z \\sim \\mathcal{N}(0, I), \\quad \\sigma_t = \\text{const}$\n",
    "    - Here $\\hat{\\mathbf{x}}_{t-1}$ - predicted image at step $t-1$\n",
    "    - $\\varepsilon_{\\theta}$ is the vector of predicted noise\n",
    "    - $\\sigma_t z$ - is a regularization element, for better training of the network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3150737-9fac-42fc-996b-a9d9eb0b0c34",
   "metadata": {},
   "source": [
    "**Loss (MSE)**\n",
    "- $L_t = \\|\\mathbf{x}_{t-1} - \\hat{\\mathbf{x}}_{t-1}\\|_2^2 \\propto \\|\\boldsymbol{\\varepsilon} - \\boldsymbol{\\varepsilon}_{\\theta}(\\mathbf{x}_t, t)\\|_2^2 \\rightarrow \\min_{\\theta}$\n",
    "    - $\\boldsymbol{\\varepsilon}_{\\theta}(\\mathbf{x}_t, t)\\$ - image, time "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b8ac0b-783d-4754-abc2-9e503a0d1674",
   "metadata": {},
   "source": [
    "![https://arxiv.org/pdf/2006.11239.pdf](content/img4006_Algo.png \"Algo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a507e3c4-1e79-4850-a4eb-6a5682fdcd68",
   "metadata": {},
   "source": [
    "We predict epsilon for the image and predict the conditional distribution, given that we already know the image \\(X_t\\). \\\n",
    "It can't be done analytically, i.e., predicting the parameters of this distribution (for example, using the maximum likelihood method) is difficult because:\r\n",
    "\r\n",
    "- The distribution is conditional.\r\n",
    "- It has high dimensionality.\r\n",
    "\r\n",
    "Therefore, neural networks are used—they solve the likelihood optimization prb\\\n",
    "lem. Moreover, we need to do this multiple times, calculating the conditional distribution, the conditionally conditional distribution etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5827a4d7-8406-4593-aa04-5f7c692b327f",
   "metadata": {},
   "source": [
    "**Hyperparameters**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c01d46-feca-43d5-a616-a53017affc7b",
   "metadata": {},
   "source": [
    "- $ T = 1000 $\n",
    "- $ \\beta_1 < \\beta_2 < \\cdots < \\beta_t < \\cdots < \\beta_T $\n",
    "- $ \\beta_1 = 0.0001, \\beta_T = 0.02 $\n",
    "- $ \\sigma_t^2 = \\beta_t \\quad \\text {or} \\quad \\sigma_t^2 = \\tilde{\\beta}_t $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db33bc1-fd86-4f7d-b9c0-2ebed27c8b7c",
   "metadata": {},
   "source": [
    "**Conditional Diffusion Models (with text)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4193d723-50d0-45ce-85a3-c546506e4055",
   "metadata": {},
   "source": [
    "**Loss (MSE)**\n",
    "- $L_t = \\|\\mathbf{x}_{t-1} - \\hat{\\mathbf{x}}_{t-1}\\|_2^2 \\propto \\|\\boldsymbol{\\varepsilon} - \\boldsymbol{\\varepsilon}_{\\theta}(\\mathbf{x}_t, t)\\|_2^2 \\rightarrow \\min_{\\theta}$\n",
    "    - $\\boldsymbol{\\varepsilon}_{\\theta}(\\mathbf{x}_t, t)\\$ - картинка, время, условие (эмбеддинг из трансформера из текста)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a215e6-a658-45d3-a9bc-3f87ecc3d54f",
   "metadata": {},
   "source": [
    "## Stable Diffusion Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38252aba-4a08-4036-87e1-7180bc866bba",
   "metadata": {},
   "source": [
    "![https://generativeai.pub/denoising-diffusion-probabilistic-models-from-scratch-728df8228565](content/img4007_Imp1.webp \"Imp1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86b659e-5983-4cdd-8c77-e3ee6f3c4d2c",
   "metadata": {},
   "source": [
    "![https://medium.com/augmented-startups/stable-diffusion-the-engine-powering-ai-influencer-stardom-ee64b4f76101](content/img4008_Imp2.png \"Imp2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9eeb5f8-c66e-4a6f-bf1e-3c5c65f11529",
   "metadata": {},
   "source": [
    "**Основные блоки**\n",
    "- **Encoder (E)** – превращает изображение из пиксельного пространства в латентный вектор (сжатое представление)\n",
    "- **Latent Space** – здесь происходит диффузия: добавляется шум к латенту (прямой процесс), затем денойзинг восстанавливает его (обратный процесс)\n",
    "- **Denoising U-Net** – denoising UNet. Она состоит из downsample блоков, mid-блока и upsample блоков. \\\n",
    "  Каждый из таких блоков является смесью нескольких последовательных resnet и cross-attention блоков. \\\n",
    "  Последние используются, чтобы модель начала реагировать на какой-то внешний сигнал, например, на эмбеддинги текстового промпта.\n",
    "- **Conditioning / Transformer (Tθ)** – добавляет условие (текст, семантическая карта, другое изображение) для управления генерацией\n",
    "- **Decoder (D)** – превращает очищенный латент обратно в сгенерированное изображение."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b70dab-8f69-42ad-96e0-8e3b34e323e8",
   "metadata": {},
   "source": [
    "**Версии моделей**\n",
    "1. **Stable Diffusion v1.1 - v1.5** ([CompViz репозиторий](https://github.com/CompVis/stable-diffusion), [RunwayML репозиторий](https://github.com/runwayml/stable-diffusion)). Обучение проходило на подвыборке из [LAION-Aesthetics V2](https://laion.ai/blog/laion-aesthetics/#laion-aesthetics-v2) в разрешении 512x512. Модель использует подход с $\\epsilon$-предсказанием.\n",
    "2. **Stable Diffusion v2.0 - v2.1** ([StabilityAI репозиторий](https://github.com/Stability-AI/stablediffusion)). Обучение осуществлялось на подвыборке [LAION-5B](https://laion.ai/blog/laion-5b/) в разрешении 768x768. Модель применяет подход с $v$-предсказанием. Она становится больше, обучается с нуля и использует более тяжелую версию [OpenCLIP](https://github.com/mlfoundations/open_clip) вместо OpenAI CLIP.\n",
    "3. **Stable Diffusion XL** ([StabilityAI репозиторий](https://github.com/Stability-AI/generative-models), [arXiv:2307.01952](https://arxiv.org/abs/2307.01952)). Модель имеет другую архитектуру и работает в две стадии: base и refiner. Включает в себя целых 2 CLIP text encoder’а. При обучении использовались дополнительные трюки — Micro-Conditioning и [SDEdit](https://arxiv.org/abs/2108.01073). Обучение проходило в разрешении 1024x1024. Модель снова стала применять подход с $\\epsilon$-предсказанием. \n",
    "4. **Stable Diffusion 3** ([блогпост](https://stability.ai/news/stable-diffusion-3), [arxiv.org:2403.03206](https://arxiv.org/pdf/2403.03206)). Сейчас модель не находится в публичном доступе, но доступна по API и показывает потрясающие результаты. Из основных изменений: заметно изменена архитектура модели (используется DiT вместо Unet и 3 text encoder’а, в процессе инференса сам text condition обрабатывается вместе с латентами параллельно, обучение базируется на концепции Rectified Flo\n",
    "5. **Stable Diffusion XL Turbo** ([StabilityAI HF](https://huggingface.co/stabilityai/sdxl-turbo)) - Упрощённая и ускоренная версия SDXL, работает за 1–4 шага генерации. Использует подход Adversarial Diffusion Distillation (ADD) и ориентирована на реалтайм\n",
    "\n",
    "---\n",
    "**Попробуйте реализовать Diffusion модель сами: https://habr.com/ru/articles/860400/**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ea03c4-2f6a-4e43-b771-1c39dd846139",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### [**AUTOMATIC1111 / Stable Diffusion web UI**](https://github.com/AUTOMATIC1111/stable-diffusion-webui)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21c08ba-349e-464a-81a0-66ef5860dc82",
   "metadata": {},
   "source": [
    "![https://deepschool-pro.notion.site/Stable-Diffusion-961e8a9430a64119ad76999652c658c3](content/img4009_AUTOMATIC1111.jpg \"AUTOMATIC1111\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4862d2c-877a-4d14-8def-d84878c8ba0e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### [**ComfyUI**](https://github.com/comfyanonymous/ComfyUI)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c702d1c-fa70-40e6-bcf6-07c11b1a3a73",
   "metadata": {},
   "source": [
    "![https://deepschool-pro.notion.site/Stable-Diffusion-961e8a9430a64119ad76999652c658c3](content/img4010_ComfyUI.jpg \"ComfyUI\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f73d497-9117-47df-a458-35318713c1c9",
   "metadata": {},
   "source": [
    "### [**Diffusers**](https://huggingface.co/docs/diffusers/en/index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a801fa-c035-49b1-b217-7829e611d24b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3eb62cd-5eab-4eec-a567-939d1d376ef9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9077be3b-acdf-4586-970a-25cbe5150fe5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af70d73a-ae41-4da1-9f69-88c1f8ee17ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a73cea-3c3d-4789-b032-4149c9daadad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05711ab-346b-45e1-a649-583aceba8413",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b3cba7-3aef-4e90-8a73-56dcaae53fbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e1a532-f824-4850-9a4e-094ae1189f2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174bb03d-7a93-4148-845a-7a25476bdd4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8faf786-244a-4623-9167-3cf9bbea8328",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4682288f-9987-4566-9740-cc2a074526cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "98ece94d-14ac-4087-ab87-4a362b39704f",
   "metadata": {},
   "source": [
    "## Projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe44e11-f734-4d10-a0bd-2eeb9f7aba0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53089ad9-5c38-47b4-9130-ee01549d603e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521d2dca-c8c4-4cf8-b31f-87911c3289ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a9bf7054-cea5-4f69-a9a3-cc071b874270",
   "metadata": {},
   "source": [
    "# Links"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f00f8d7-f765-44a1-a14f-2aa7c8a415a0",
   "metadata": {},
   "source": [
    "- https://www.youtube.com/watch?v=z7QH-WWHmfE\n",
    "- https://theaisummer.com/diffusion-models/\n",
    "- https://deepschool-pro.notion.site/Stable-Diffusion-961e8a9430a64119ad76999652c658c3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a31df2d-dff0-4512-8cb8-a760fa466713",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dc90b1b3-be7a-4bb7-b075-3d04e579413f",
   "metadata": {},
   "source": [
    "**Evaluation**\n",
    "\n",
    "- https://huggingface.co/docs/diffusers/en/conceptual/evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3e8b78-3cd8-4261-adc5-8218028ec6fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f40c96-8dd2-427c-aa7d-73fe9e4783a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "51a05fdc-1abb-471d-b973-329826b8ad25",
   "metadata": {},
   "source": [
    "# END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b0bd0d-0645-4d06-b574-fd01b8654e11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbeb1c8-a2c1-4bcc-9a29-d89e1cf2a76c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58cc3af-b7ad-43ed-a229-ea075907c9e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae645cb4-3749-477a-b0de-642484b1443c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "py311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
